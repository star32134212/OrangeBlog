---
layout: post
title: Test Orange
tags: 
  - "history"
---

pipeline note
=== 

Spark MLlib已經算是簡單易懂的套件，但如果要處理的資料集很複雜需要多次處理或是要建置模型需要搭配其他模型的話，MLlib會變得很複雜，Pipeline可以將每個資料處理過程和模型視為一個stage，讓複雜的過程變得簡單易懂。  
Pipeline的組件可分為兩種：  
**Transfer**  
包含特徵轉換和學習後的模型預測，例如定義好assembler這個特徵提取過程後，使用**transform**來對資料進行特徵轉換。  
```
assembler = VectorAssembler(inputCols = feature_name, outputCol = 'features')
ass_train = assembler.transform(train)
```
模型訓練好後可以視為一個資料轉換的過程，特徵資料進去預測結果出來，因此也是用**transform**對資料進行預測。  
```
predicted = pipelineModel.transform(test)
```
**Estimator**  
對資料進行訓練的過程，包含所有的機器學習方法，例如MLP,DecisionTree等，使用**fit**或**train**進行訓練。  
```
dt_model = dt.fit(final_traindata)
```
使用 **featureImportances** 可知道在建構tree的過程中，哪些參數是重要的，以此來判定什麼因素對客戶點擊房間的決定影響比較大。  
```
dt_model.featureImportances
```
將每個Pipeline的組件決定好後，可以使用stages講每個組件拼成一個過程，此時的PipelineModel已經可以視為一個包含資料處理的完整預測模型。  
```
pipeline = Pipeline(stages=[assembler,dt])
pipelineModel = pipeline.fit(train)
```
我們可以得到每個流程更詳細的資訊，例如印出decition tree的決策過程。
```
print(pipelineModel.stages[1].toDebugString)
```
<img width="600" height="350" src="https://github.com/star32134212/SparkML_Pipeline/blob/master/img/dt_process.png"/> 
### Decision Tree
binary_evaluator Decision Tree Acc: 0.4552  
multi_evaluator Decision Tree Acc: 0.9542  

#### decition tree對click_bool判斷的前十重要特徵：
('prop_location_score1', 0.1542)  
('prop_location_score2', 0.1239)  
('price_usd', 0.0737)  
('prop_starrating', 0.0629)  
('prop_review_score', 0.0578)  
('srch_destination_id', 0.0559)  
('prop_log_historical_price', 0.0500)  
('srch_booking_window', 0.0454)  
('srch_length_of_stay', 0.0405)  
('srch_children_count', 0.0394)  
### Random Forest
binary_evaluator Random Forest Acc: 0.6365  
multi_evaluator Random Forest Acc: 0.9565  
  
#### random forest對click_bool判斷的前十重要特徵：  
('prop_location_score2', 0.2665)  
('prop_location_score1', 0.1358)  
('prop_starrating', 0.0598)  
('price_usd', 0.0593)  
('promotion_flag', 0.0585)  
('prop_review_score', 0.0452)  
('prop_log_historical_price', 0.0403)  
('srch_room_count', 0.0386)  
('srch_adults_count', 0.0354)  
('srch_length_of_stay', 0.0336)  

### GBT
binary_evaluator Gradient-boosted Trees Acc: 0.6537  
multi_evaluator Gradient-boosted Trees Acc: 0.9557  

#### GBT對click_bool判斷的前十重要特徵：  
('prop_location_score2', 0.0825)  
('prop_location_score1', 0.0807)  
('price_usd', 0.0679)  
('srch_destination_id', 0.0678)  
('srch_booking_window', 0.0610)  
('hour', 0.0573)  
('prop_review_score', 0.0548)  
('srch_adults_count', 0.0537)  
('prop_starrating', 0.0523)  
('srch_children_count', 0.0513)  

### 小結
(1)可以知道三種方法覺得重要的特徵前兩名是一樣的，都是score1和score2。  
(2)三種模型對feature會有不同的見解，例如GBT認為使用者在何時訂房是一個重要的參數，將它排在第六名，其他兩模型則沒上榜。  
(3)讓決策樹的深度加深反而會使acc下降，可能是因為在train資料及分太細，影響對test資料分類的acc，有overfitting的可能。  
